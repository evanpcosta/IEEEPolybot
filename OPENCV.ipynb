{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import os \n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.gaussian_process import GaussianProcessRegressor \n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from skimage import io, img_as_float \n",
    "import imquality.brisque as brisque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Image/bad1.png\", 0) #if u pass in 1 as 2nd argument it gives original image and 0 gives greyscale image \n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# cv2.imwrite(\"Image/test.png\", img) #create a new file but the openCV environemnt changes the encoding so the size of these files are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)\n",
    "len(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black = np.zeros([500, 200, 1], 'uint8')\n",
    "cv2.imshow(\"Black\", black)\n",
    "print(black[0,0:])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Code to seperate Good and Bad Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010859245666450683\n"
     ]
    }
   ],
   "source": [
    "img = img_as_float(io.imread('Image/bad1.png', as_gray=True))\n",
    "\n",
    "print(img.var())\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010859245666450683\n",
      "0.003700628557076839\n",
      "6.344487567988743e-05\n",
      "7.722142677156263e-05\n",
      "0.0011284648811054365\n",
      "0.0011071940174921368\n",
      "6.901009376203697e-05\n",
      "0.0011125890157333285\n"
     ]
    }
   ],
   "source": [
    "li = [\"bad1\", \"bad2\", \"good3\", \"good4\",\"good5\",\"good6\",\"good7\",\"good8\"]\n",
    "for i in li: \n",
    "    img = img_as_float(io.imread('Image/'+ i + '.png', as_gray=True))\n",
    "    print(img.var())\n",
    "#0.002 as the threshold for differentiating good and bad images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.52033686 0.51162275 ... 0.51492549 0.50844353 0.51750078]\n",
      " [1.         0.51081922 0.4949149  ... 0.51197647 0.50609059 0.50256471]\n",
      " [1.         0.50353373 0.50225922 ... 0.44317216 0.46900902 0.49885059]\n",
      " ...\n",
      " [1.         0.41288941 0.42052588 ... 0.50033765 0.50342588 0.47479765]\n",
      " [1.         0.26533765 0.26222667 ... 0.50062039 0.50257765 0.49186078]\n",
      " [1.         0.36696157 0.34477137 ... 0.50818078 0.50286745 0.50788314]]\n"
     ]
    }
   ],
   "source": [
    "img1 = img_as_float(io.imread('Image/bad2.png', as_gray=True))\n",
    "\n",
    "print(img1)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert CSV to JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Json(csvFilePath, jsonFilePath):\n",
    "    with open(csvFilePath, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = {\"id:\" , \n",
    "               \"timestamp:\", \n",
    "               \"workflow:\", \n",
    "               \"locate:\"}\n",
    "        for row in reader: \n",
    "            #this is the actual process of creating the JSON file \n",
    "            key = \"\"\n",
    "            data[key] = rows \n",
    "    with open(jsonFilePath, \"w\") as jsonf: \n",
    "        json.dump(data, jsonf, indent=4) #passing in the dictionary as the first argument, the name of the json file as 2nd arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\alanx\\\\OneDrive\\\\Desktop\\\\keras\\\\IEEE'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
